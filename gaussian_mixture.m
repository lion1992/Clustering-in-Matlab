 
function [initialparams, initialmemberships, gparams,memberships] =  gaussian_mixture(X,K,init_method,epsilon, niterations,plotflag, RSEED)
% [gparams,memberships] =  gaussian_mixture(data,K,init_method,epsilon, 
%                                                niterations,plotflag, RSEED)
%
% Template for a function to fit  a Gaussian mixture model via EM 
% using K mixture components. The data are contained in the N x d "data" matrix. 
%  
% INPUTS
%  data: N x d real-valued data matrix
%  K: number of clusters (mixture components)
%  initialization_method: 1 for memberships, 2 for parameters, 3 for kmeans 
%  epsilon: convergence threshold used to detect convergence
%  niterations (optional): maximum number of iterations to perform (default 500)
%  plotflag (optional): equals 1 to plot parameters during learning, 
%                       0 for no plotting (default is 0)
%  RSEED (optional): initial seed value for the random number generator
%  
%
% OUTPUTS
%  initialparams:  2d structure array containing the initial mixture model parameters: 
%  initialmemberships: N x K matrix of initial probability memberships for "data"
%  gparams:  2d structure array containing the learned mixture model parameters: 
%           gparams(k).weight = weight of component k
%           gparams(k).mean = d-dimensional mean vector for kth component 
%           gparams(k).covariance = d x d covariance vector for kth component
%  memberships: N x K matrix of probability memberships for "data"
%
%  Note: Interpretation of gparams and memberships:
%    - gparams(k).weight is the probability that a randomly selected row
%         belongs to component (or cluster) i (so it is "cluster size")
%    - memberships(i,k) = p(cluster k | x) which is the probability
%         (computed via Bayes rule) that vector x was generated by cluster
%         k, according to the "generative" probabilistic model. 

% your code goes here....
if(nargin<5 || isempty('niterations'))
    niterations = 500;
end
if(nargin<6 || isempty('plotflag'))
    plotflag = 0;
end

% initialize....
[N, D] = size(X);
counter = 1;
% Initiate parameters and memberships using the specified initialization
% method;
[initialparams, initialmemberships] = Initialization(X, K, init_method);
loglikelihood = logL(X,initialparams,K);
oldMember = initialmemberships;
oldParams = initialparams;
newParams = struct('weight', {}, 'mean', {}, 'covariance', {});
if(init_method == 1)
    % in the case where memberships were first initiated and then the
    % parameters were initiated according to the members;
    % so here we need to update memberships first;

    done = false;
    while (done == false)
        for(k = 1:K)
            % E step;
            for (i = 1:N)
                newMember(i,k) = getMembership(X(i,:), k, oldParams, K);
            end
            % M step;
            weight = sum(newMember(:,k))/N;
            Nk = weight * N;
            mean = (newMember(:,k)' * X)/Nk;
            covariance = 1/Nk * ((repmat(newMember(:,k),[1, D]))' .* (X - repmat(mean,[N,1]))' * (X - repmat(mean,[N,1])));
            newParams(k).weight = weight;
            newParams(k).mean = mean;
            newParams(k).covariance = covariance;
        end
        logLinProgress = logL(X,newParams,K);
        loglikelihood = [loglikelihood, logLinProgress];
        counter = counter + 1;
        stopcriterion = sum(sum(abs(oldMember - newMember)))/(N*K*D);
        if(stopcriterion<epsilon || counter>1000)
           done = true;
           gparams = newParams;
           memberships = newMember;
        else
           oldParams = newParams;
           oldMember = newMember;
        end
    end
else
    % since parameters were first initiated, in the Initialization function,
    % the next step was initiating the memberships, so here we start with
    % the M step.
    done = false;
    while (done == false)
        % M step;
        for(k = 1:K)
            weight = sum(oldMember(:,k))/N;
            Nk = weight * N;
            mean = (oldMember(:,k)' * X)/Nk;
            covariance = 1/Nk * ((repmat(oldMember(:,k),[1, D]))' .* (X - repmat(mean,[N,1]))' * (X - repmat(mean,[N,1])));
            newParams(k).weight = weight;
            newParams(k).mean = mean;
            newParams(k).covariance = covariance;
        end
        % E step;
        for (k = 1:K)
            for (i = 1:N)
                newMember(i,k) = getMembership(X(i,:), k, newParams, K);
            end
        end
        % Compute loglikelihood of this iteration;
        logLinProgress = logL(X,newParams,K);
        loglikelihood = [loglikelihood, logLinProgress];
        counter = counter + 1;
        
        % check if stopping criterion are met;
        if((sum(sum(abs(oldMember - newMember))))/(N*K) < epsilon || counter > niterations)
           done = true;
           gparams = newParams;
           memberships = newMember;
        else
           oldParams = newParams;
           oldMember = newMember;
        end
    end

end

if(plotflag == 1)
    plot(1:counter, loglikelihood, 'b-');
    hold on;
    ylabel('Loglikelihood');
    xlabel( 'Iteration');
    title ('Loglikelihood vs. Iteration');
    hold off
end
end

